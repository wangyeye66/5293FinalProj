[["index.html", "IMLV Final Project Chapter 1 Proposal Descriptions 1.1 About Dataset 1.2 Modeling Goal 1.3 Methods 1.4 Read data from Excel file 1.5 Data Cleaning 1.6 Data pre-processing 1.7 Exploratory Data Analysis 1.8 Change Categorical to Numerical 1.9 Checking for Principal Components 1.10 Drop Outliers 1.11 Save Cleaned Data", " IMLV Final Project Han Wang 2023-04-30 Chapter 1 Proposal Descriptions 1.1 About Dataset Data: The data I am going to use in my final project is called Online Retail Data Set from UCI ML repo. Here’s the link for the dataset: https://archive.ics.uci.edu/ml/datasets/online+retail Source: Dr Daqing Chen, Director: Public Analytics group. chend ‘@’ lsbu.ac.uk, School of Engineering, London South Bank University, London SE1 0AA, UK. Information: This is a transnational data set which contains all the transactions occurring between 01/12/2010 and 09/12/2011 for a UK-based and registered non-store online retail.The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers. 1.2 Modeling Goal Through this project, I would like to learn how sales will differ based on month, week, time, unit price and quantity. I will use three models to predict the sales, ranging from the least interpretable one(Random Forest) to the most(Linear Regression). By evaluating the accuracy of each model, this project will answer the following questions: Do the models have concurrent or conflicting interpretations? Can you explain why? Do some models offer more insight than others? Is it worth losing interpretability/increasing model complexity? Can the simpler model do just as well? Why or why not? To what extent is it possible to answer your questions of interest with the models you have chosen? What are their limitations? 1.3 Methods Random Forest Regression Decision Trees Regression Linear Regression 1.4 Read data from Excel file After loading the data, use summary() to get an overview of it. ## InvoiceNo StockCode Description Quantity ## Length:541909 Length:541909 Length:541909 Min. :-80995.00 ## Class :character Class :character Class :character 1st Qu.: 1.00 ## Mode :character Mode :character Mode :character Median : 3.00 ## Mean : 9.55 ## 3rd Qu.: 10.00 ## Max. : 80995.00 ## ## InvoiceDate UnitPrice CustomerID ## Min. :2010-12-01 08:26:00.00 Min. :-11062.06 Min. :12346 ## 1st Qu.:2011-03-28 11:34:00.00 1st Qu.: 1.25 1st Qu.:13953 ## Median :2011-07-19 17:17:00.00 Median : 2.08 Median :15152 ## Mean :2011-07-04 13:34:57.16 Mean : 4.61 Mean :15288 ## 3rd Qu.:2011-10-19 11:27:00.00 3rd Qu.: 4.13 3rd Qu.:16791 ## Max. :2011-12-09 12:50:00.00 Max. : 38970.00 Max. :18287 ## NA&#39;s :135080 ## Country ## Length:541909 ## Class :character ## Mode :character ## ## ## ## ## InvoiceNo StockCode Description Quantity InvoiceDate UnitPrice ## 0 0 1454 0 0 0 ## CustomerID Country ## 135080 0 There are many NAs in the column CustomerID. Since this column is irrelavent to our analysis, we can simply remove it. 1.5 Data Cleaning Remove NULL values from the data, and reprint the summary of the data. ## InvoiceNo StockCode Description Quantity ## Length:539394 Length:539394 Length:539394 Min. :-80995.00 ## Class :character Class :character Class :character 1st Qu.: 1.00 ## Mode :character Mode :character Mode :character Median : 3.00 ## Mean : 9.85 ## 3rd Qu.: 10.00 ## Max. : 80995.00 ## InvoiceDate UnitPrice Country ## Min. :2010-12-01 08:26:00.0 Min. :-11062.06 Length:539394 ## 1st Qu.:2011-03-28 11:59:00.0 1st Qu.: 1.25 Class :character ## Median :2011-07-20 11:50:00.0 Median : 2.08 Mode :character ## Mean :2011-07-04 16:40:48.7 Mean : 4.63 ## 3rd Qu.:2011-10-19 11:49:00.0 3rd Qu.: 4.13 ## Max. :2011-12-09 12:50:00.0 Max. : 38970.00 1.6 Data pre-processing I changed the description and country column to factor, and did the datetime processing. In particular, I extracted the column InvoiceDate, separating out four new columns: date, month, week, and time. The Sales column is then calculated using Quantity and UnitPrice. ## # A tibble: 6 × 12 ## InvoiceNo StockCode Descri…¹ Quant…² InvoiceDate UnitP…³ Country date ## &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dttm&gt; &lt;dbl&gt; &lt;fct&gt; &lt;chr&gt; ## 1 536365 85123A WHITE H… 6 2010-12-01 08:26:00 2.55 United… 12/0… ## 2 536365 71053 WHITE M… 6 2010-12-01 08:26:00 3.39 United… 12/0… ## 3 536365 84406B CREAM C… 8 2010-12-01 08:26:00 2.75 United… 12/0… ## 4 536365 84029G KNITTED… 6 2010-12-01 08:26:00 3.39 United… 12/0… ## 5 536365 84029E RED WOO… 6 2010-12-01 08:26:00 3.39 United… 12/0… ## 6 536365 22752 SET 7 B… 2 2010-12-01 08:26:00 7.65 United… 12/0… ## # … with 4 more variables: month &lt;chr&gt;, week &lt;chr&gt;, time &lt;chr&gt;, Sales &lt;dbl&gt;, ## # and abbreviated variable names ¹​Description, ²​Quantity, ³​UnitPrice 1.7 Exploratory Data Analysis 1.7.1 Most sold Products The bar plot above depicts the top ten most popular products on this online retail website. According to the plot, the most popular product is the ‘White Hanging Heart T-Light Holder,’ with approximately 2500 units sold. The products ‘Regency Cakestand 3 Tier’ and ‘Jumbo Bag Red Retrospot’ are also popular on the online retail website. 1.7.2 Costomer base across the countries Given that almost all users are from the United Kingdom, it would be nearly impossible to predict sales using the country factor. As a result, we will remove the country column from this project. 1.7.3 Total Sales by Hour Note that the original dataset does not include sales information from 9 p.m. to 6 a.m. It is possible that this is due to website maintenance, or someone may have excluded this data due to the low number of sales during those hours. The line graph depicts total sales by hour. The majority of sales occur between 10 a.m. and 3 p.m. This makes logical because people are more active during this time period. It’s worth noting that this line plot is quite symmetric. People are less likely to buy in the early morning and late at night. 1.7.4 Total Sales by Day AS mentioned before, the dataset does not include sales information of Saturday due to similar reasons. The line plot Total Sales by Day depicts costomers’ shopping habit. Sales are higher form Monday to Thursday, while sales drops significantly on Friday and weekends. 1.7.5 Total Sales by Month This line plot depicts the month-to-month change in online retail sales. The figure shows that sales are high from September to December. The peak month is November. This figure makes sense because there are numerous festivities from September through December, such as Christmas, Thanksgiving, and New Year’s. We can deduce that people shop for gifts online. Another trend in the figure is a significant dip in January, and total sales for the remainder of the year are relatively low. It is most likely due to limited budgets and a lack of festivals from January to August. 1.8 Change Categorical to Numerical ## Quantity UnitPrice month week time ## Quantity 1.000000000 -0.0013182520 -0.0013951922 -0.001704601 -0.011389930 ## UnitPrice -0.001318252 1.0000000000 -0.0005349981 -0.007358089 0.001305487 ## month -0.001395192 -0.0005349981 1.0000000000 0.040133430 0.025958983 ## week -0.001704601 -0.0073580891 0.0401334297 1.000000000 -0.033158359 ## time -0.011389930 0.0013054875 0.0259589828 -0.033158359 1.000000000 I converted categorical data to numerical data in this stage. For example, ‘December’ equals 12, ‘Monday’ equals 1, and so on. The variables are next checked for multicollinearity by calculating the correlations between them. Except for the diagnal, the values in the above table are very low. As a result, we concluded that all of the variables are unrelated, and we should keep them. 1.9 Checking for Principal Components ## Importance of components: ## PC1 PC2 PC3 PC4 PC5 ## Standard deviation 1.0210 1.0142 0.9996 0.9986 0.9658 ## Proportion of Variance 0.2085 0.2057 0.1998 0.1994 0.1865 ## Cumulative Proportion 0.2085 0.4142 0.6140 0.8135 1.0000 The Scree plot is almost a linear curve, that means we have good choice of dependent variables. 1.10 Drop Outliers When I was implementing the first model, I noticed that the original dataset has a large number of outliers. To improve prediction precision, I removed the first and fourth quantiles from the original data and then sampled 5000 data points from the modified data. 1.11 Save Cleaned Data The original dataset has around 540,000 pieces of data, to make it computationally efficient, I randomly selected 5000 data, and saved it as csv file. "],["model-1-random-forest.html", "Chapter 2 [Model 1] Random Forest 2.1 Perform Random Forest Regression 2.2 Random Forest Regression Evaluation 2.3 Interpretation of Random Forest Model", " Chapter 2 [Model 1] Random Forest 2.1 Perform Random Forest Regression ## ## Call: ## randomForest(formula = Sales ~ ., data = trainset, ntree = 1000, importance = TRUE) ## Type of random forest: regression ## Number of trees: 1000 ## No. of variables tried at each split: 1 ## ## Mean of squared residuals: 2390.745 ## % Var explained: 21.33 ## [1] &quot;The RMSE is: 55.0840742993363&quot; We can see from the image above that there are many outliers in our data, which reduces prediction performance. Furthermore, the RMSE for this model is around 55.08 and only 21.33% of variance can be explained by this model. We must eliminate the outliers to get a better result. For the next two models, I will only use the dataset without the outliers. 2.2 Random Forest Regression Evaluation ## ## Call: ## randomForest(formula = Sales ~ ., data = trainset.adj, ntree = 1000, importance = TRUE) ## Type of random forest: regression ## Number of trees: 1000 ## No. of variables tried at each split: 1 ## ## Mean of squared residuals: 14.41007 ## % Var explained: 80.05 ## [1] &quot;The RMSE is: 3.87657226207381&quot; We can see from the above figure that the data points center together after we remove the outliers and retrain the random forest model. The variance explained by the model reach to 80%. The RMSE drops to 3.87. Overall, the prediction accuracy improves significantly. 2.3 Interpretation of Random Forest Model PDP Partial Dependence Plot is a type of data visualization technique commonly used in machine learning to understand the relationship between a target variable and one or more predictor variables. We can deduce from the Partial Dependence Plot that there is a logarithmic growth relationship between UnitPrice and the intended variable, Sales. In other words, when the UnitPrice rises, Sales will rise logarithmically. When it comes to the relationship between Quantity and Sales, when Quantity ranges between 0 and 25, Sales will increase dramatically. Sales will increase gradually for quantities of more than 25. As time increases, there is a steady diminishing tendency. That is, customers tend to buy less at the end of the day. The plot also implies that the month and week have little influence on total sales because their lines are very flat. VIP Variance Importance Plot is a graphical representation of the importance of each predictor variable in a statistical or machine learning model. The graphic makes it obvious that quantity, followed by unit price and time, is the most crucial factor in predicting total sales. The time variable is much less significant than the other two, though. Finally, week and month are two factors that are not important in the Ramdom Forest Regression model. This plot conveys the results from the Partial Dependence Plot. "],["model-2-tree-regression.html", "Chapter 3 [Model 2] Tree Regression 3.1 Perform Tree Regression 3.2 Tree Regression Evaluation 3.3 Interpretation of Tree Regression Model", " Chapter 3 [Model 2] Tree Regression 3.1 Perform Tree Regression The regression tree plot is impossible to interpret. By setting cp = 0, the expanded as much as it could without being pruned. Although we human are unable to interpret any information from the plot, the machine will understand it thoroughly, and offer accurate predictions. 3.2 Tree Regression Evaluation ## [1] &quot;The RMSE is: 1.60491397575623&quot; When we plot the predict values against the true values, we observe that it forms a diagnal line. This means the predict values are really close to the true values. The result of RMSE is only 1.6, also suggesting that the model has great performance in predicting Sales based on Quantity, UnitPrice, month, week and time. 3.3 Interpretation of Tree Regression Model VIP The Variance Importance Plot suggests that only Quantity and UnitPrice are important in the Tree Regression model. The other three variables are neglected in this model. SHAP SHAP (SHapley Additive exPlanations) is a method that explains how individual predictions are made by a machine learning model. SHAP deconstructs a prediction into a sum of contributions from each of the model’s input variables. From the above plot, we may infer that Quantity and UnitPrice had significant impacts on the model’s prediction. Note that these two variables also have large standard deviation. We may conclude that most of the variance in Sales come from these two variables. Similar to the results from VIP, month, week and time do not have enough influence in prediction. "],["model-3-linear-regression.html", "Chapter 4 [Model 3] Linear Regression 4.1 Perform Linear Regression 4.2 Linear Regression Evaluation 4.3 Interpretation of Linear Model", " Chapter 4 [Model 3] Linear Regression 4.1 Perform Linear Regression ## ## Call: ## lm(formula = Sales ~ ., data = trainset) ## ## Residuals: ## Min 1Q Median 3Q Max ## -41.719 -3.981 -1.925 3.700 24.141 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 8.56692 0.69483 12.330 &lt;2e-16 *** ## Quantity 0.57554 0.01329 43.309 &lt;2e-16 *** ## UnitPrice 1.23683 0.03434 36.017 &lt;2e-16 *** ## month -0.01528 0.03016 -0.507 0.612 ## week -0.04336 0.05700 -0.761 0.447 ## time -0.41700 0.04425 -9.424 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 6.512 on 3789 degrees of freedom ## Multiple R-squared: 0.4139, Adjusted R-squared: 0.4131 ## F-statistic: 535.1 on 5 and 3789 DF, p-value: &lt; 2.2e-16 4.2 Linear Regression Evaluation ## [1] &quot;The RMSE is: 7.54447481182564&quot; We can simply interpret the the liner model by reading its summary. According to our sampled data, every unit increase in Quantity increases total sales by 0.65. The total sale will increase by 1.26 for every unit increase in UnitPrice. The total sale will reduce by 0.38 for every unit increase in time. However, in a linear regression model, the factors month and week have no significance in predicting sales.The p-values for month and week also suggests that there is no association between total sales and these two factors in a linear regression model. The RMSE is 7.54, which is the highest compared to the previous two models. From the predicted values vs. true values plot, the linear model underestimate the total sales. 4.3 Interpretation of Linear Model The Variance Importance Plot of Linear Regression model is similar to Random Forest Regression model. Quantity and UnitPrice are still two most important variable in predicting Sales. The importance of time is low, but not as negligible as it was in Tree Regression model. "],["reflections.html", "Chapter 5 Reflections 5.1 A Summary Three Models 5.2 Discussion", " Chapter 5 Reflections 5.1 A Summary Three Models Model RMSE run_time interpretability Random Forest Regression 3.87 5.305508 secs Hard Tree Regression 1.60 0.044229 secs Medium Linear Regression 7.54 0.002125 secs Easy Tree Regression has the greatest performance of the three Regression Models, and it took 0.076 seconds for Tree model to fit 5000 pieces of data. Random Forest Regression came in second, however the model is so complex that it takes 5.33 seconds to fit 5000 data points. Random Forest Regression would take even longer if we used the original dataset (500,000 data points). Even while we can use tools like VIP, PDP, and LIME to visualize and analyze Random Forest, we cannot gain a whole view of it. Linear Regression is incredibly efficient in terms of run time and is also simple to interpret. Our data collection, on the other hand, is clearly non-linear. As a result, the RMSE for Linear Regression is the highest among three. The Online Retail Data Set appears to be best suited for Tree Regression. It performs well in predicting new data, and fitting a tree model takes less time than Random Forest. We can learn how each factor contributes to the model using the tools VIP and SHAP. 5.2 Discussion Do the models have concurrent or conflicting interpretations? Can you explain why? Yes, different models can have concurrent or conflicting interpretations because they rely on different assumptions, data, and algorithms. For example, a linear regression model might suggest that there is a linear relationship between two variables, while a nonlinear model might suggest a more complex relationship. Do some models offer more insight than others? Yes, for the data set used in this project, Tree Regression offers more insight. It is able to capture the mechanisms or processes hiding under the data set. Is it worth losing interpretability/increasing model complexity? Can the simpler model do just as well? Why or why not? It depends. We prone to choose simpler model if it perform as good as a more complex one, because simpler models are: robust to overfitting. easier to understand and communicate to others. less computationally expensive to train and use. 5.2.1 Limitation We don’t have enough variation in the variable types, which is one of the project’s limitations. For instance, three of the five variables are about the time. By adding more types of variables, complex model, such as Random Forest, would have a better performance. The second drawback is that I’m unable to fine-tune the hyperparameter. ‘max_depth’ in Random Forest, for instance. Additionally, the computational complexity of my model prevents me from using bootstrapping. Finally, out data set used is not large enough. This will introduce limited variability, overfitting, and unrepresentative samples. 5.2.2 Future Directions We might focus more on optimizing the hyperparameters for complex models in the future. This will improve the prediction capabilities of complex models. We can add extra models to the project as well, which will help us determine which one is most appropriate. Finally, we need to incorporate more variables and data sets into our project. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
